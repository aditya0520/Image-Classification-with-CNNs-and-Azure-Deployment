{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HIXLYNLTmgBo"
   },
   "source": [
    "# Machine Learning on CPU vs GPU and Cloud Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, you will practice with using PyTorch for training ML models and Azure resources for deploying models. Your deliverables will be a set of trained models as well as a public API endpoint that anyone can send their input data to, in order to get prediction results from the models. As a reminder, the entirety of this project should be done on a `Standard_NC4as_T4_v3` GPU compute in the Azure Machine Learning Studio. You may not get the same output as the test cases if you use Google Colab or your own GPU. However, it is still useful to first run your code on an external environment to check that there are no runtime errors. If you are new to PyTorch, you will likely run into many data type or dimension errors, which you don't want to debug while an Azure GPU compute is running and draining your budget."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NjDxpvH7i_4o"
   },
   "source": [
    "## Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gather": {
     "logged": 1711778942648
    },
    "id": "Puf3cmksrEBx"
   },
   "outputs": [],
   "source": [
    "# load necessary modules\n",
    "import os, time, json, copy, pickle, random, requests, re\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gather": {
     "logged": 1711778942859
    },
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you see Numpy version 1.22.4 and PyTorch version 2.0.1 in the following cell; using different versions may cause you to fail the local tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gather": {
     "logged": 1711778943004
    },
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.24.0\n",
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "print(np.__version__)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b5vowlO5Q7IJ"
   },
   "source": [
    "We first create a `device` variable which automatically uses GPU, if one is available, and CPU otherwise. This helps us switch between CPU and GPU seamlessly without needing any explicit code changes.\n",
    "\n",
    "You should assume that all the functions from Q1 - Q11 use GPU by default, unless otherwise specified. Therefore, make sure that the output of the next cell is `device(type='cuda')`. If it is not, you should double check the compute which you are using to run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "gather": {
     "logged": 1711778943224
    },
    "id": "wvAPGsHGY8zw",
    "outputId": "7e258f17-f02e-4bf6-f363-caa12798c49f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0v8CbCapRzBm"
   },
   "source": [
    "Next, we provide some functions to set the seed of several random generators. We will call these functions at the beginning of every test case to ensure that your code generates consistent output. You do not need to call `set_seed` in any of your implementation code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gather": {
     "logged": 1711778943466
    },
    "id": "KI--Me1UXjgg"
   },
   "outputs": [],
   "source": [
    "GLOBAL_SEED = 1\n",
    " \n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "GLOBAL_WORKER_ID = None\n",
    "def _init_fn(worker_id):\n",
    "    global GLOBAL_WORKER_ID\n",
    "    GLOBAL_WORKER_ID = worker_id\n",
    "    set_seed(GLOBAL_SEED + worker_id)\n",
    "\n",
    "set_seed(GLOBAL_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SYzs7pN9mqc_"
   },
   "source": [
    "## Section A: Dataset Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CZZQfKmIWNT_"
   },
   "source": [
    "The dataset we use here is a subset of [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html), which contains 50000 32x32 RGB images belonging to 10 mutually exclusive classes (e,g., plane, car, bird). The dataset is divided into four training batches and one validation batch, each with 10000 images. Each of the batch files contains a dictionary with the following elements:\n",
    "\n",
    "**Input data** -- a $10000 \\times 3072$ matrix of type `uint8s`. Each row of the array stores a flattened 32x32 RGB image as follows:\n",
    "\n",
    "$$\\underbrace{x_1, x_2, \\ldots, x_{1024}}_{\\text{red channel}} \\underbrace{x_{1025}, x_{1026} \\ldots x_{2048}}_{\\text{green channel}} \\underbrace{x_{2049} x_{2050} \\ldots x_{3072}}_{\\text{blue channel}}$$\n",
    "Each image is stored in row-major order, so that the first 32 entries of the array are the first row of the red channel values of the image.\n",
    "\n",
    "To get more intuition about this structure, let's consider a colored $2 \\times 2$ image, which can be represented as a $3 \\times 2 \\times 2$ matrix:\n",
    "```py\n",
    "image = [\n",
    "    [[1, 2], [3, 4]], #red channel\n",
    "    [[5, 6], [7, 8]], # blue channel\n",
    "    [[9, 10], [11, 12]] # green channel\n",
    "]\n",
    "```\n",
    "When flattening this image we get the vector\n",
    "```py\n",
    "v = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "```\n",
    "\n",
    "This flattened represenation is what the data files store. So, in the context of CIFAR-10, a batch of data with $10000$ images would be a matrix with shape $$10000 \\times 1024$$.\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"https://production-media.paperswithcode.com/datasets/4fdf2b82-2bc3-4f97-ba51-400322b228b1.png\">\n",
    "</p>\n",
    "\n",
    "**Output labels** -- a list of $10000$ labels in the range $0-9$. The number at index $i$ indicates the label of the $i$-th image in the input data. We provide a mapping from the label index to the actual label in the list `classes` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gather": {
     "logged": 1711778943683
    },
    "id": "L8lxJ2FAWK__"
   },
   "outputs": [],
   "source": [
    "train_files = ['data/train_batch_1','data/train_batch_2','data/train_batch_3','data/train_batch_4']\n",
    "val_files = ['data/validation_batch']\n",
    "\n",
    "## class names\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warm-up: reconstructing a flattened image\n",
    "Because the images have been flattened, our first step in reading the data is to undo this transformation. Following up on the example above, if you have the flattened vector\n",
    "\n",
    "```py\n",
    "v = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "```\n",
    "\n",
    "and the size of the original image ($3 \\times 2 \\times 2$), you should be able to reconstruct the original 3D matrix:\n",
    "\n",
    "```py\n",
    "image = [\n",
    "    [[1, 2], [3, 4]],\n",
    "    [[5, 6], [7, 8]],\n",
    "    [[9, 10], [11, 12]]\n",
    "]\n",
    "```\n",
    "\n",
    "Implement the function `reconstruct_3D_images` that performs this reconstruction on a given batch of images. To ensure efficiency, you should not loop through individual images in the batch; instead, identify a NumPy method to reconstruct the entire batch at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "gather": {
     "logged": 1711778943892
    }
   },
   "outputs": [],
   "source": [
    "def reconstruct_3D_images(flatted_images, depth, width, height):\n",
    "    \"\"\"\n",
    "    Reconstruct a batch of 3D images given their flattened vector and the original image dimensions\n",
    "    \n",
    "    args:\n",
    "        flatted_images (np.ndarray) : a batch of images, each flattened from 3D to 1D\n",
    "        width (int) : the width of the original 3D image\n",
    "        height (int) : the height of the original 3D image\n",
    "        depth (int) : the depth of the original 3D image\n",
    "    \n",
    "    returns:\n",
    "        np.ndarray : a 4D matrix of shape (N, depth, height, width)\n",
    "            where N is the batch size\n",
    "    \"\"\"\n",
    "    reconstructed_images = flatted_images.reshape(-1, depth, height, width)\n",
    "    return reconstructed_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test this function on the synthetic example above and on an actual image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "gather": {
     "logged": 1711778944276
    },
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ship_original.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m     plt\u001b[38;5;241m.\u001b[39mimshow(np\u001b[38;5;241m.\u001b[39mtranspose(reconstructed_images[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m), (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m)))\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou should see a blurry image of a ship\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 25\u001b[0m test_reconstruct_3D_images()\n",
      "Cell \u001b[0;32mIn[8], line 16\u001b[0m, in \u001b[0;36mtest_reconstruct_3D_images\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m reconstructed_images \u001b[38;5;241m=\u001b[39m reconstruct_3D_images(flattened_images, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m reconstructed_images\u001b[38;5;241m.\u001b[39mtolist() \u001b[38;5;241m==\u001b[39m [img1, img2]\n\u001b[0;32m---> 16\u001b[0m img1 \u001b[38;5;241m=\u001b[39m img2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mship_original.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     17\u001b[0m flattened_images \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([np\u001b[38;5;241m.\u001b[39mloadtxt(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mship_flattened.txt\u001b[39m\u001b[38;5;124m'\u001b[39m), np\u001b[38;5;241m.\u001b[39mloadtxt(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mship_flattened.txt\u001b[39m\u001b[38;5;124m'\u001b[39m)])\n\u001b[1;32m     18\u001b[0m reconstructed_images \u001b[38;5;241m=\u001b[39m reconstruct_3D_images(flattened_images, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m32\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/numpy/lib/npyio.py:405\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    403\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 405\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28mopen\u001b[39m(os_fspath(file), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    406\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ship_original.npy'"
     ]
    }
   ],
   "source": [
    "def test_reconstruct_3D_images():\n",
    "    img1 = [\n",
    "        [[0, 1], [2, 3], [4, 5], [6, 7]],\n",
    "        [[8, 9], [10, 11], [12, 13], [14, 15]],\n",
    "        [[16, 17], [18, 19], [20, 21], [22, 23]]\n",
    "    ]\n",
    "    img2 = [\n",
    "        [[24, 25], [26, 27], [28, 29], [30, 31]],\n",
    "        [[32, 33], [34, 35], [36, 37], [38, 39]],\n",
    "        [[40, 41], [42, 43], [44, 45], [46, 47]]\n",
    "    ]\n",
    "    flattened_images = np.array([np.arange(24), np.arange(24, 48)])\n",
    "    reconstructed_images = reconstruct_3D_images(flattened_images, 3, 2, 4)\n",
    "    assert reconstructed_images.tolist() == [img1, img2]\n",
    "    \n",
    "    img1 = img2 = np.load('ship_original.npy').tolist()\n",
    "    flattened_images = np.array([np.loadtxt('ship_flattened.txt'), np.loadtxt('ship_flattened.txt')])\n",
    "    reconstructed_images = reconstruct_3D_images(flattened_images, 3, 32, 32)\n",
    "    assert reconstructed_images.tolist() == [img1, img2]\n",
    "    print(\"All tests passed\")\n",
    "    \n",
    "    plt.imshow(np.transpose(reconstructed_images[0].astype(int), (1, 2, 0)))\n",
    "    print(\"You should see a blurry image of a ship\")\n",
    "    \n",
    "test_reconstruct_3D_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yz8ixuLnXjgl"
   },
   "source": [
    "### Question 1: Preparing data for PyTorch\n",
    "\n",
    "\n",
    "PyTorch has an abstract class called [Dataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) which we can subset to specify our own data preprocessing pipeline. Implement the methods `__init__()`, `__len__()`, and `__getitem__()` in the `ImageDataset` class so that:\n",
    "\n",
    "* `__init__` reads all the data from a given list of filenames and creates two instance variables, `self.data` and `self.labels`. \n",
    "    * `self.data` is a container for the dataset, which is constructed by:\n",
    "        1. Reading the data file of flattened images in the input filename list.\n",
    "        1. Reconstructing the 3D representations of all flattened images.\n",
    "        1. Performing an appropriate transpose to obtain the final shape `(n_images, height, width, n_channels)`.\n",
    "\n",
    "    * `self.labels` is a 1D Python list of image labels.\n",
    "\n",
    "* `__len()__` should return the number of images in the dataset. We have implemented this function for you.\n",
    "\n",
    "* `__getitem()__` takes as input an index `idx` and returns the data point at index `idx`, which is a tuple of `(image, label)`, where `image` is a normalized tensor and `label` is a label index from 0-9.\n",
    "    * To transform an image from NumPy matrix format to normalized tensor format, you should make use of the instance variable `self.transform` provided in the `__init__` function. Check the [torchvision.transforms](https://pytorch.org/vision/stable/transforms.html) for example usage.\n",
    "\n",
    "**Notes:**\n",
    "* Each CIFAR data file can be opened with the `pickle` module, using the `latin1` encoding. The extracted file will be a dictionary, `d`. `d[\"data\"]` is a NumPy array of flattened images with shape `(n_images, 3072)`, while `d[\"labels\"]` is a Python list of `n_images` labels.\n",
    "* If the Sail() autograder says that your code produces empty output with no error message, you are using too much memory. Make sure to close any file you open, and keep in mind that NumPy methods that return a new array in memory (such as `np.concatenate` and `np.stack`) should not be used inside a loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gather": {
     "logged": 1711778944434
    },
    "id": "wwzXHZuBjRqE"
   },
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_files):\n",
    "        \"\"\"\n",
    "        Initializes self.data as a container for the dataset and self.labels as a container for the labels.\n",
    "\n",
    "        args: \n",
    "             data_files (List[str]): list of data filenames to read from\n",
    "        \"\"\"\n",
    "        # do not modify this code\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "        \n",
    "        # your code here\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "\n",
    "        # Load and preprocess data from files\n",
    "        for file_name in data_files:\n",
    "            with open(file_name, 'rb') as f:\n",
    "                batch = pickle.load(f, encoding='latin1')  # Ensure compatibility\n",
    "                # Reshape and transpose data to (n_images, height, width, n_channels)\n",
    "                images = batch['data'].reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)\n",
    "                self.data.append(images)\n",
    "                self.labels.extend(batch['labels'])\n",
    "                \n",
    "        # Convert data list to a numpy array for efficient indexing in __getitem__\n",
    "        self.data = np.concatenate(self.data, axis=0)\n",
    "     \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Get the dataset length.\n",
    "\n",
    "        return:\n",
    "            int : the number of images in the dataset\n",
    "        \"\"\"\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Fetch and transform the data sample at the given index.\n",
    "\n",
    "        args:\n",
    "            idx (int): index to get an image data\n",
    "\n",
    "        return:\n",
    "            Tuple(img, label):\n",
    "                img (torch.Tensor) : a normalized tensor of size (n_channels, height, width)\n",
    "                label (int) : the label of img\n",
    "        \"\"\"\n",
    "        image = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            # Convert image to PIL Image for compatibility with torchvision transforms\n",
    "            image = Image.fromarray(image.astype('uint8'), 'RGB')\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "gather": {
     "logged": 1711778946688
    },
    "id": "l4HcJi8BZRLu",
    "outputId": "4af4eb8a-c874-4e63-92b5-6385c2b0cc10",
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed!\n"
     ]
    }
   ],
   "source": [
    "def dataset_test():\n",
    "    trainset = ImageDataset(train_files)\n",
    "    valset = ImageDataset(val_files)\n",
    "    assert trainset.data.dtype == np.uint8\n",
    "    assert trainset.data.shape == (40000, 32, 32, 3)\n",
    "    assert set(trainset.labels) == set(range(10))\n",
    "    assert (trainset.labels[:5] == np.array([6, 9, 9, 4, 1])).all()\n",
    "    assert trainset.data.shape == (40000, 32, 32, 3)\n",
    "    assert valset.data.shape == (10000, 32, 32, 3)\n",
    "    assert len(trainset) == 40000\n",
    "    assert len(valset) == 10000\n",
    "\n",
    "    # get training image at index 2\n",
    "    assert trainset[2][0][0][:3][:,:3].equal(torch.tensor([\n",
    "        [1.0, 0.9843137264251709,0.9843137264251709 ],\n",
    "        [1.0, 1.0,1.0],\n",
    "        [1.0, 0.9921568632125854, 0.9921568632125854]\n",
    "    ]))\n",
    "    # get training label at index 2\n",
    "    assert trainset[2][1] == 9\n",
    "\n",
    "    # get validation image at index 2\n",
    "    assert valset[2][0][0][:3][:,:3].equal(torch.tensor([\n",
    "        [-0.09019607305526733, -0.498039186000824, -0.8509804010391235],\n",
    "        [-0.10588234663009644, -0.498039186000824, -0.8588235378265381],\n",
    "        [-0.10588234663009644, -0.5137255191802979, -0.8666666746139526]\n",
    "    ]))\n",
    "    # get validation label at index 2\n",
    "    assert valset[2][1] == 5\n",
    "    print('All tests passed!')\n",
    "\n",
    "dataset_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9tYfn-hcXjgr"
   },
   "source": [
    "### Question 2: Create Dataloader\n",
    "\n",
    "Now that we have the training and validation set, the next step is to split them into minibatches, so that we can iterate over each minibatch in our training. PyTorch has a [DataLoader class](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) to support this process. Implement the function `get_dataloader` that uses DataLoader to create iterables over the training and validation set with the given batch size.\n",
    "\n",
    "**Notes**:\n",
    "* When creating a DataLoader instance, the `shuffle` option should be `True` for the training set and `False` for the validation set.\n",
    "* You should also set `worker_init_fn` to `_init_fn` (recall that we have provided the `_init_fn` implementation for you in the code cell above Part A) and `num_workers` to the provided `num_workers` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gather": {
     "logged": 1711778946835
    },
    "id": "37Rr-d6HjeBJ"
   },
   "outputs": [],
   "source": [
    "def get_dataloader(trainset, valset = None, batch_size = 64, num_workers = 2):\n",
    "    \"\"\"\n",
    "    Create iterators over the minibatches of the training and validation data.\n",
    "    \n",
    "    arg:\n",
    "        trainset (ImageDataset): instance of ImageDataset with training data\n",
    "    \n",
    "    kwargs:\n",
    "        valset (ImageDataset): instance of ImageDataset with validation data, can be None\n",
    "        batch_size (int): number of images per minibatch\n",
    "        num_workers (int): the number of subprocesses used for data loading\n",
    "\n",
    "    return: \n",
    "        Tuple(train_loader, val_loader):\n",
    "            train_loader (DataLoader): iterable for trainset minibatches\n",
    "            val_loader (DataLoader): iterable for valset minibatches, or None if valset is None\n",
    "    \"\"\"\n",
    "    train_loader = DataLoader(\n",
    "        trainset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        worker_init_fn=_init_fn\n",
    "    )\n",
    "    \n",
    "    val_loader = None\n",
    "    if valset is not None:\n",
    "        val_loader = DataLoader(\n",
    "            valset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,  # No need to shuffle validation data\n",
    "            num_workers=num_workers,\n",
    "            worker_init_fn=_init_fn\n",
    "        )\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "gather": {
     "logged": 1711778949764
    },
    "id": "JLtTUSAt4VlR",
    "outputId": "bc3fa4ab-29ae-4a04-ca57-a72d3710a439",
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed!\n"
     ]
    }
   ],
   "source": [
    "def dataloader_test():\n",
    "    set_seed(GLOBAL_SEED)\n",
    "    trainset = ImageDataset(train_files)\n",
    "    valset = ImageDataset(val_files)\n",
    "    train_loader, val_loader = get_dataloader(trainset, valset)\n",
    "    \n",
    "    assert train_loader.dataset == trainset\n",
    "    assert train_loader.batch_size == 64\n",
    "\n",
    "    train_images, train_labels = next(iter(train_loader))\n",
    "    assert train_labels[:5].equal(torch.tensor([7, 3, 3, 4, 2]))\n",
    "\n",
    "    val_images, val_labels = next(iter(val_loader))\n",
    "    assert val_labels[4:9].equal(torch.tensor([5, 7, 4, 3, 8]))\n",
    "    print('All tests passed!')\n",
    "\n",
    "dataloader_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uIRqZNRvn-mQ"
   },
   "source": [
    "## Section B: Model Implementation\n",
    "In this part, we will implement three classifier models using PyTorch, which include a logistic regression model and two convolutional network architectures, LeNet and AlexNet.\n",
    "\n",
    "To begin, we provide a function that counts the number of parameters in a given model. We will use this to get a better idea of how many parameters are typically required for this kind of image classification task.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gather": {
     "logged": 1711778949930
    },
    "id": "wrm6bzzVnE8X"
   },
   "outputs": [],
   "source": [
    "# do not modify this function\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zrXc4epKoGDG"
   },
   "source": [
    "### Question 3: Logistic regression\n",
    "Recall from the primer that we can treat a logistic regression model as a neural network with a single linear layer (and softmax activation function). Implement the class `LogisticRegression` with this structure.\n",
    "\n",
    "**Notes**:\n",
    "* If the input data to `forward` is a multi-dimensional tensor, it needs to be flattened before being passed to the linear layer.\n",
    "* The softmax activation function is not a part of the `LogisticRegression` class itself, since it is covered in the cross entropy loss which we will use later in training. Therefore, `LogisticRegression` will only have a linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gather": {
     "logged": 1711778950092
    },
    "id": "dBN6yjHpoUaH"
   },
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        \"\"\"\n",
    "        Initialize the network layers.\n",
    "\n",
    "        args:\n",
    "            input_dim (Tuple): the shape (n_channels, height, width) of a sample data point\n",
    "            output_dim (int): the number of nodes in the output layer\n",
    "        \"\"\"\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        # Calculate the total number of input features from the input dimensions.\n",
    "        self.total_input_features = input_dim[0] * input_dim[1] * input_dim[2]\n",
    "        \n",
    "        # Define the linear layer with the calculated number of input features and specified output dimensions.\n",
    "        self.linear = nn.Linear(self.total_input_features, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Get the output of the forward pass\n",
    "\n",
    "        args:\n",
    "            x (array-like): a batch of input data\n",
    "\n",
    "        return:\n",
    "            tensor[float]: a tensor with output_dim elements, output from the forward pass of this network\n",
    "        \"\"\"\n",
    "        # Flatten the input tensor to ensure it's a 2D tensor where each row represents a flattened image.\n",
    "        x = x.view(-1, self.total_input_features)\n",
    "        # Pass the input through the linear layer.\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "gather": {
     "logged": 1711778950228
    },
    "id": "lDfaJi54hng4",
    "outputId": "38a2cebb-15a3-470c-fe01-1b935632117c",
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed!\n"
     ]
    }
   ],
   "source": [
    "def test_logistic_regression():\n",
    "    set_seed(GLOBAL_SEED)\n",
    "    data = (torch.rand(1, 3, 32, 32) * 255)\n",
    "    lr_model = LogisticRegression((3, 32, 32), 10)\n",
    "    output = lr_model(data).detach().numpy()\n",
    "    expected_output = np.array([[\n",
    "        103.10795,   -114.899765,     9.040313,   173.60179,     58.90976,\n",
    "        -99.95934,     10.475531,    25.296503,   -12.6308775,   40.47077\n",
    "    ]])\n",
    "    \n",
    "    assert count_parameters(lr_model) == 30730\n",
    "    assert output.shape == expected_output.shape\n",
    "    assert np.allclose(output, expected_output)\n",
    "    print(\"All tests passed!\")\n",
    "    \n",
    "test_logistic_regression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j3NcsqcNoFrU"
   },
   "source": [
    "### Question 4: LeNet\n",
    "We now implement a variation of a classic CNN architecture called [LeNet](http://yann.lecun.com/exdb/lenet/), which consists of the following layers:\n",
    "\n",
    "1. Input layer.\n",
    "1. Convolutional layer with $K = 6, F = 5, S = 1, P = 0$.\n",
    "1. ReLU layer.\n",
    "1. Maxpool layer with $F = S = 2$.\n",
    "1. Convolutional layer with $K = 16,  F = 5, S = 1, P = 0$.\n",
    "1. ReLU layer.\n",
    "1. Maxpool layer with $F = S = 2$.\n",
    "1. Linear layer with 120 ouput nodes.\n",
    "1. ReLU layer.\n",
    "1. Linear layer with 84 output nodes.\n",
    "1. ReLU layer.\n",
    "1. Linear layer with `output_dim` output nodes.\n",
    "\n",
    "Implement the class `LeNet` based on the outline above.\n",
    "\n",
    "**Notes**:\n",
    "* Refer to the dimension computations in Section 2.4.2 of the [Deep Learning and Computer Vision primer](https://nbviewer.jupyter.org/url/clouddatascience.blob.core.windows.net/primers/dl-cv-primer/dl_cv_primer.ipynb) to see how to determine the output dimension of a layer based on its input dimension and hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gather": {
     "logged": 1711778950371
    },
    "id": "EtrBVFsZoVOf"
   },
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        \"\"\"\n",
    "        Initialize the network layers.\n",
    "\n",
    "        args:\n",
    "            input_dim (Tuple): the shape (n_channels, height, width) of a sample data point\n",
    "            output_dim (int): the number of nodes in the output layer\n",
    "        \"\"\"\n",
    "        pass\n",
    "        super(LeNet, self).__init__()\n",
    "        \n",
    "        # Define the layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=input_dim[0], out_channels=6, kernel_size=5, stride=1, padding=0)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # Output dimension calculation: ((input_dim[1] - 4) / 2 - 4) / 2 * ((input_dim[2] - 4) / 2 - 4) / 2 * 16\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(84, output_dim)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Get the output of the forward pass\n",
    "\n",
    "        args:\n",
    "            x (array-like): a batch of input data\n",
    "\n",
    "        return:\n",
    "            tensor[float]: a tensor with output_dim elements, output from the forward pass of this network\n",
    "        \"\"\"\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = x.view(-1, 16 * 5 * 5)  # Flatten the tensor for the fully connected layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "gather": {
     "logged": 1711778950514
    },
    "id": "7vfW3PBciCZt",
    "outputId": "91e11fd2-d2f1-4211-e76e-246c030719fd",
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed!\n"
     ]
    }
   ],
   "source": [
    "def test_lenet():\n",
    "    set_seed(GLOBAL_SEED)\n",
    "    data = (torch.rand(1, 3, 32, 32) * 255)\n",
    "    lenet = LeNet((3, 32, 32), 10)\n",
    "    expected_output = np.array([[\n",
    "        -4.061032772064209, 1.5774850845336914, 2.344625949859619, -2.4299728870391846, 3.5291049480438232,\n",
    "        0.5699751377105713, -2.208556652069092, 4.889535903930664, 2.7112417221069336, -1.9356430768966675\n",
    "    ]])\n",
    "    output = lenet(data).detach().numpy()\n",
    "\n",
    "    assert count_parameters(lenet) == 62006\n",
    "    assert output.shape == expected_output.shape\n",
    "    assert np.allclose(output, expected_output)\n",
    "    print(\"All tests passed!\")\n",
    "    \n",
    "test_lenet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i4fLaIsooWkh"
   },
   "source": [
    "### Question 5: AlexNet\n",
    "Our third model is a variation of another CNN architecture called [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf), which consists of the following layers:\n",
    "\n",
    "1. Input layer\n",
    "1. Convolutional layer, $K = 64, F = 3, S = 2, P = 1$.\n",
    "1. ReLU layer\n",
    "1. Maxpool layer, $F = S = 2$.\n",
    "1. Convolutional layer, $K = 192, F = 3, S = 1, P = 1$.\n",
    "1. ReLU layer\n",
    "1. Maxpool layer, $F = S = 2$\n",
    "1. Convolutional layer, $K = 384, F = 3, S = 1, P = 1$\n",
    "1. ReLU layer\n",
    "1. Convolutional layer, $K = 256, F = 3, S = 1, P = 1$\n",
    "1. ReLU layer\n",
    "1. Convolutional layer, $K = 256, F = 3, S = 1, P = 1$\n",
    "1. ReLU layer\n",
    "1. Maxpool layer, $F = S = 2$\n",
    "1. Dropout layer\n",
    "1. Linear layer with 4096 output nodes\n",
    "1. ReLU layer\n",
    "1. Dropout layer\n",
    "1. Linear layer with 1024 output nodes\n",
    "1. ReLU layer\n",
    "1. Linear layer with `output_dim` output nodes\n",
    "\n",
    "**Notes**:\n",
    "* Note the use of a dropout layer, which randomly zeroes some of the elements of the input tensor with probability $p = 0.5$ during training, in order to prevent overfitting. This is supported by `torch.nn.Dropout`.\n",
    "* To save memory, you can set `inplace = True` in the ReLU layers (but don't specify this parameter in the Dropout layers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gather": {
     "logged": 1711778950648
    },
    "id": "FEioi5DWsxLQ"
   },
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        \"\"\"\n",
    "        Initialize the network layers.\n",
    "\n",
    "        args:\n",
    "            input_dim (Tuple): the shape (n_channels, n_height, n_width) of a sample data point\n",
    "            output_dim (int): the number of nodes in the output layer\n",
    "        \"\"\"\n",
    "        super(AlexNet, self).__init__()\n",
    "\n",
    "        # Feature extraction part\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_dim[0], out_channels=64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        # Classifier part\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            # Assuming the input image size is 32x32, adjust the first Linear layer size if different.\n",
    "            nn.Linear(256 * 2 * 2, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(1024, output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Get the output of the forward pass\n",
    "\n",
    "        args:\n",
    "            x (array-like): a batch of input data\n",
    "\n",
    "        return:\n",
    "            tensor[float]: a tensor with output_dim elements, output from the forward pass of this network\n",
    "        \"\"\"\n",
    "        x = self.features(x)  # Pass the input through the feature extractor\n",
    "        x = torch.flatten(x, 1)  # Flatten the output for the classifier\n",
    "        x = self.classifier(x)  # Pass the flattened output through the classifier\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "gather": {
     "logged": 1711778950792
    },
    "id": "jsOxDkWgiTMl",
    "outputId": "7c08388b-0d63-406f-9873-a8de7c3e9a35",
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10655562\n",
      "[[ 0.2438528  -0.430624   -0.39223298  0.07139769  1.065471   -1.2516557\n",
      "   0.54295635 -0.12359155 -1.2486346   0.21474946]]\n",
      "All tests passed!\n"
     ]
    }
   ],
   "source": [
    "def test_alexnet():\n",
    "    set_seed(GLOBAL_SEED)\n",
    "    data = (torch.rand(1, 3, 32, 32) * 255)\n",
    "    alexnet = AlexNet((3, 32, 32), 10)\n",
    "    expected_output = np.array([[\n",
    "        0.2438529,  -0.43062437, -0.39223233,  0.0713978, 1.065471,\n",
    "        -1.2516553, 0.5429566, -0.12359135, -1.2486352, 0.21474946\n",
    "    ]])\n",
    "    output = alexnet(data).detach().numpy()\n",
    "\n",
    "    assert output.shape == expected_output.shape\n",
    "    print(count_parameters(alexnet))\n",
    "    assert count_parameters(alexnet) == 10655562\n",
    "    print(output)\n",
    "    assert np.allclose(output, expected_output), output\n",
    "    print(\"All tests passed!\")\n",
    "    \n",
    "test_alexnet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fTtY4nnOoRHz"
   },
   "source": [
    "We see that there is quite a discrepancy between these three models' parameter counts: logistic regression has close to 30 thousands; LeNet has close to 60 thousands, while AlexNet has more than 10 million parameters. Let's see if the additional parameters also correspond to improved performance in our task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l1yOr1_6vhQY"
   },
   "source": [
    "## Section C: Training Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FDi-OnMP7nJO"
   },
   "source": [
    "We now initialize the components for model training as global variables. First we will create the training and validation sets as instances of `ImageDataset`. Second, as this is a multi-class classification problem, we will use cross entropy as our loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gather": {
     "logged": 1711778951981
    },
    "id": "h56idfSbUsf0"
   },
   "outputs": [],
   "source": [
    "set_seed(GLOBAL_SEED)\n",
    "full_trainset, full_valset = ImageDataset(train_files), ImageDataset(val_files)\n",
    "input_dim, output_dim = (3, 32, 32), 10\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QH3Rv3618XSS"
   },
   "source": [
    "### Question 6: Train model for one epoch\n",
    "\n",
    "We define a helper function to perform model training in one epoch, i.e., going through all minibatches once. Implement the function `train_one_epoch` which loops over all the minibatches in a given `DataLoader` to train a model and records the average training loss, the training accuracy, as well as training time.\n",
    "\n",
    "**Note:**\n",
    "* Before looping through the minibatches, make sure to call `model.train()` to set your model to training mode. While this mode is enabled by default, later on we will alternate between training and validation, so it is good practice to be explicit about the model's mode every time.\n",
    "* Remember to move all the input data and label to `device` as you loop through `train_loader`. To move a tensor `x` to `device`, you can run `x = x.to(device)` (note the reassignment is necessary here).\n",
    "* The average training loss is defined as the sum of loss values across all minibatches, divided by the number of minibatches.\n",
    "* After training in each minibatch, you can compute the number of correctly classified images in that minibatch (recall from Project 4 that the predicted label of a data point corresponds to the highest hypothesis value). The training accuracy is defined as the number of correctly classified images across the entire dataset, divided by the dataset size.\n",
    "* You should record the start time at the start of the function (with `time.time()`) and end time before the return statement. The difference between these time points is considered the training time.\n",
    "* If your code passes the logistic regression test case but failes the AlexNet test case in the local test on Azure, the issue may be in your AlexNet implemention; make sure to follow the Q5 specifications closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gather": {
     "logged": 1711778952120
    },
    "id": "_Ckamrvrs4tg"
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, optimizer):\n",
    "    \n",
    "    \"\"\"\n",
    "    Train a given model on all minibatches provided by a dataloader \n",
    "    \n",
    "    args:\n",
    "        model (nn.Module): an instance of a model class (LogisticRegression, LeNet or AlexNet)\n",
    "        train_loader (DataLoader): iterable for trainset minibatches\n",
    "        optimizer (optim.Optimizer): an instance of an optimizer class in torch.optim\n",
    "    \n",
    "    return: Tuple(avg_train_loss, train_accuracy, train_time)\n",
    "        avg_train_loss (float): average training loss across batches\n",
    "        train_accuracy (float): portion of correctly classified images in the training dataset\n",
    "        train_time (float): the time taken to run this function\n",
    "    \"\"\"\n",
    "    model.train()  # Set the model to training mode\n",
    "    device = next(model.parameters()).device  # Get the device of the model\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    start_time = time.time()  \n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)  \n",
    "        optimizer.zero_grad()  \n",
    "        \n",
    "        \n",
    "        output = model(data)\n",
    "        \n",
    "       \n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "       \n",
    "        loss.backward()\n",
    "        \n",
    "       \n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = output.max(1)\n",
    "        total += target.size(0)\n",
    "        correct += predicted.eq(target).sum().item()\n",
    "    \n",
    "    end_time = time.time()  \n",
    "    train_time = end_time - start_time  \n",
    "    \n",
    "   \n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    train_accuracy = correct / total\n",
    "    \n",
    "    return avg_train_loss, train_accuracy, train_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "gather": {
     "logged": 1711778955502
    },
    "id": "m2YgL5-ZACBP",
    "outputId": "067338eb-eb09-4bff-d76c-644f00f27f9a",
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed!\n"
     ]
    }
   ],
   "source": [
    "def test_train_one_epoch():\n",
    "    set_seed(GLOBAL_SEED)\n",
    "    # training logistic regression model\n",
    "    lr_model = LogisticRegression(input_dim, output_dim)\n",
    "    lr_model.to(device)\n",
    "\n",
    "    optimizer = optim.Adam(lr_model.parameters(), lr=0.001, weight_decay = 5e-4)\n",
    "    trainset = ImageDataset([train_files[0]])\n",
    "    train_loader, _ = get_dataloader(trainset)\n",
    "    avg_train_loss, train_accuracy, train_time = train_one_epoch(lr_model, train_loader, optimizer)\n",
    "\n",
    "    assert np.allclose(avg_train_loss, 1.9157349903872058), avg_train_loss\n",
    "    assert train_accuracy == 0.3331, train_accuracy\n",
    "    \n",
    "    set_seed(GLOBAL_SEED)\n",
    "    # training AlexNet model\n",
    "    alexnet = AlexNet(input_dim, output_dim)\n",
    "    alexnet.to(device)\n",
    "    optimizer = optim.Adam(alexnet.parameters(), lr=0.001, weight_decay = 5e-4)\n",
    "    train_loader, _ = get_dataloader(trainset)\n",
    "    avg_train_loss, train_accuracy, train_time = train_one_epoch(alexnet, train_loader, optimizer)\n",
    "    assert np.allclose(avg_train_loss,  1.9889057122977676), avg_train_loss\n",
    "    assert train_accuracy == 0.22, train_accuracy\n",
    "    print('All tests passed!')\n",
    "\n",
    "test_train_one_epoch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WWOXivJEh4iH"
   },
   "source": [
    "### Question 7: Validate the trained model\n",
    "\n",
    "After training a model, we need to evaluate its generalizability with the validation data. Given a trained model and validation dataloader, implement the function `validate_model()` that uses the trained model to predict the validation labels, returning the validation loss, accuracy and running time.\n",
    "\n",
    "**Note:**\n",
    "\n",
    "* Similar to `train_one_epoch`, you should record the start time at the begining and end time before returning, then calculate their difference as the validation time.\n",
    "* Before looping through the minibatches, make sure to call `model.eval()` to set your model to evaluation mode, and also call `with torch.no_grad()` to disable gradient computation (note the `with` is necessary here, see the PyTorch primer on how to use this call).\n",
    "* Remember to move all the input data and label to `device` as you loop through `val_loader`. To move a tensor `x` to `device`, you can run `x = x.to(device)`.\n",
    "* If your code passes the logistic regression test case but failes the AlexNet test case in the local test on Azure, the issue may be in your AlexNet implemention; make sure to follow the Q5 specifications closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gather": {
     "logged": 1711778955652
    },
    "id": "pBEo4lyZt9gO"
   },
   "outputs": [],
   "source": [
    "def validate_model(model, val_loader):  \n",
    "    \"\"\"\n",
    "    Validate a given model with a validation dataloader.\n",
    "    \n",
    "    args:\n",
    "        model (nn.Module): the trained model \n",
    "        val_loader (DataLoader): iterable for valset minibatches\n",
    "\n",
    "    return: Tuple(avg_val_loss, val_accuracy, val_time)\n",
    "        avg_val_loss (float): average validation loss across batches\n",
    "        val_accuracy (float): portion of correctly classified images in the validation dataset\n",
    "        val_time (float): the time taken to run this function\n",
    "    \"\"\"\n",
    "    model.eval()  \n",
    "    device = next(model.parameters()).device \n",
    "    \n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    start_time = time.time() \n",
    "    \n",
    "    with torch.no_grad():  \n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(device), target.to(device)  \n",
    "            \n",
    "           \n",
    "            output = model(data)\n",
    "            \n",
    "            \n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = output.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "    \n",
    "    end_time = time.time()  \n",
    "    val_time = end_time - start_time \n",
    "    \n",
    "    \n",
    "    avg_val_loss = total_loss / len(val_loader)\n",
    "    val_accuracy = correct / total\n",
    "    \n",
    "    return avg_val_loss, val_accuracy, val_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "gather": {
     "logged": 1711778960774
    },
    "id": "C11tR6n5UQec",
    "outputId": "39c0c53a-fa75-4e54-b4a6-95943ab477bd",
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed!\n"
     ]
    }
   ],
   "source": [
    "def test_validate_model():\n",
    "    set_seed(GLOBAL_SEED)\n",
    "    # validate logistic regression model\n",
    "    lr_model = LogisticRegression(input_dim, output_dim)\n",
    "    lr_model.to(device)\n",
    "\n",
    "    optimizer = optim.Adam(lr_model.parameters(), lr=0.001, weight_decay = 5e-4)\n",
    "    trainset = ImageDataset([train_files[0]])\n",
    "    valset = ImageDataset([val_files[0]])\n",
    "    train_loader, val_loader = get_dataloader(trainset, valset)\n",
    "    train_one_epoch(lr_model, train_loader, optimizer)\n",
    "\n",
    "    avg_val_loss, val_accuracy, val_time = validate_model(lr_model, val_loader)\n",
    "    assert np.allclose(avg_val_loss, 1.8939218923544427), avg_val_loss\n",
    "    assert val_accuracy == 0.3491, val_accuracy\n",
    "    \n",
    "    # validate AlexNet model\n",
    "    set_seed(GLOBAL_SEED)\n",
    "    alexnet = AlexNet(input_dim, output_dim)\n",
    "    alexnet.to(device)\n",
    "    optimizer = optim.Adam(alexnet.parameters(), lr=0.001, weight_decay = 5e-4)\n",
    "    train_loader, val_loader = get_dataloader(trainset, valset)\n",
    "    train_one_epoch(alexnet, train_loader, optimizer)\n",
    "    avg_val_loss, val_accuracy, val_time = validate_model(alexnet, val_loader)\n",
    "    assert np.allclose(avg_val_loss, 1.9927906162419897), avg_val_loss\n",
    "    assert val_accuracy == 0.2727, val_accuracy\n",
    "    \n",
    "    print('All tests passed!')\n",
    "\n",
    "test_validate_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AP1TITJemJng"
   },
   "source": [
    "### Question 8: Train model for mutiple epochs\n",
    "\n",
    "We usually train a model for multiple epochs to get better results. Implement the `train_model` function that trains a given model for `n_epochs` times, evaluates its performance at each epoch, and returns the best state of the model (i.e., the state at the epoch when the best validation accuracy is yielded).\n",
    "\n",
    "**Notes**:\n",
    "* If two model states at two different epoch numbers yield the same best validation accuracy, pick the state corresponding to the *lower* epoch number. Also note that the epoch numbers should be indexed from 1, not 0 (i.e., the first epoch is called epoch 1).\n",
    "* To save a model state, you can make a **deep copy** of its `state_dict()`, using the `copy` module imported at the start of this notebook. To load a model state, you can call `.load_state_dict()` on an instance of the same model class.\n",
    "* Note the difference between `model.load_state_dict()` and `model = model.load_state_dict()`; the latter is **incorrect**.\n",
    "* This function has a `scheduler` parameter, which is used to dynamically adjust the learning rate during training. You can see its use case in the [official documentation](https://pytorch.org/docs/stable/optim.html). In summary, if `scheduler` is not `None`, `scheduler.step()` should be called once every epoch *after* all the training iterations in that epoch have finished. In later questions, you will get to specify your own `scheduler`.\n",
    "* We also provide a `verbose` flag. If you would like to add print debugging messages during model training, put every print statement under an `if verbose` check, for example\n",
    "\n",
    "```python\n",
    "if verbose:\n",
    "    print(\"Training accuracy is\", train_acc)\n",
    "    print(\"Validation accuracy is\", val_acc)\n",
    "```\n",
    "During your work you can set `verbose = True` to help with debugging; our autograder will only call `train_model` with `verbose = False`, so that your printout messages do not interfere with the grading.\n",
    "\n",
    "* You can record the total time by summing over all the time values returned by `train_one_epoch` and `validate_models`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gather": {
     "logged": 1711778960916
    },
    "id": "BZ1bbUK5uOBu"
   },
   "outputs": [],
   "source": [
    "def train_model(model, n_epochs, train_loader, val_loader, optimizer, scheduler = None, verbose = False):\n",
    "    \"\"\"\n",
    "    Train the model for several epochs, recording the best model state and training / validation time and performance\n",
    "    \n",
    "    args:\n",
    "        model (nn.Module): an instance of a model class (LogisticRegression, LeNet or AlexNet)\n",
    "        n_epochs (int): the number of epochs to train for\n",
    "        train_loader (DataLoader): iterable for trainset minibatches\n",
    "        val_loader (DataLoader): iterable for valset minibatches\n",
    "        optimizer (optim.Optimizer): an instance of an optimizer class in torch.optim\n",
    "\n",
    "    kwargs:\n",
    "        scheduler (optim.lr_scheduler): a PyTorch scheduler that can adjust the learning rates during training\n",
    "        verbose (bool): a flag that indicates whether print statements should be executed\n",
    "\n",
    "    return:\n",
    "        Tuple(best_acc_model, best_acc_epoch_num, train_acc, train_losses, val_acc, total_time)\n",
    "            best_acc_model (nn.Module): the model with the weight parameters that yield the best validation accuracy across all epochs\n",
    "            best_acc_epoch_num (int): the epoch number where the best validation accuracy occurs (indexed from 1)\n",
    "            train_accs (List[float]): list of average training accuracy in each epoch\n",
    "            train_losses (List[float]): list of average training loss in each epoch\n",
    "            val_accs (List[float]): list of validation accuracy in each epoch\n",
    "            total_time (float): the sum of train time and validation time across all epochs\n",
    "    \"\"\"\n",
    "    import copy\n",
    "    import time\n",
    "\n",
    "    best_acc = 0.0\n",
    "    best_acc_epoch_num = 1\n",
    "    best_model_state = copy.deepcopy(model.state_dict())\n",
    "    train_accs, train_losses, val_accs = [], [], []\n",
    "    total_time = 0.0\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "       \n",
    "        train_loss, train_acc, train_time = train_one_epoch(model, train_loader, optimizer)\n",
    "        val_loss, val_acc, val_time = validate_model(model, val_loader)\n",
    "\n",
    "        \n",
    "        total_time += train_time + val_time\n",
    "\n",
    "        \n",
    "        train_accs.append(train_acc)\n",
    "        train_losses.append(train_loss)\n",
    "        val_accs.append(val_acc)\n",
    "\n",
    "        \n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_acc_epoch_num = epoch\n",
    "            best_model_state = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Epoch {epoch}: Train Loss = {train_loss:.4f}, Train Acc = {train_acc:.4f}, Val Loss = {val_loss:.4f}, Val Acc = {val_acc:.4f}\")\n",
    "\n",
    "    \n",
    "    model.load_state_dict(best_model_state)\n",
    "\n",
    "    return model, best_acc_epoch_num, train_accs, train_losses, val_accs, total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "gather": {
     "logged": 1711778987890
    },
    "id": "Sar5_UT0zgGQ",
    "outputId": "d29e245c-8c27-427e-cb63-b9bcb0abe5a3",
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 1.9889, Train Acc = 0.2200, Val Loss = 1.9928, Val Acc = 0.2727\n",
      "Epoch 2: Train Loss = 1.7057, Train Acc = 0.3352, Val Loss = 1.6658, Val Acc = 0.3604\n",
      "Epoch 3: Train Loss = 1.5514, Train Acc = 0.4103, Val Loss = 1.5507, Val Acc = 0.4106\n",
      "Epoch 4: Train Loss = 1.4573, Train Acc = 0.4582, Val Loss = 1.5362, Val Acc = 0.4442\n",
      "Epoch 5: Train Loss = 1.3638, Train Acc = 0.4977, Val Loss = 1.4217, Val Acc = 0.4689\n",
      "Epoch 1: Train Loss = 2.3026, Train Acc = 0.0980, Val Loss = 2.3030, Val Acc = 0.0957\n",
      "Epoch 2: Train Loss = 2.0861, Train Acc = 0.1804, Val Loss = 1.9253, Val Acc = 0.2325\n",
      "Epoch 3: Train Loss = 1.8550, Train Acc = 0.2667, Val Loss = 1.7412, Val Acc = 0.3061\n",
      "Epoch 4: Train Loss = 1.7613, Train Acc = 0.3117, Val Loss = 1.7655, Val Acc = 0.2990\n",
      "Epoch 5: Train Loss = 1.7447, Train Acc = 0.3212, Val Loss = 1.6988, Val Acc = 0.3472\n",
      "All tests passed!\n"
     ]
    }
   ],
   "source": [
    "def test_train_model():\n",
    "    set_seed(GLOBAL_SEED)\n",
    "    model = AlexNet(input_dim, output_dim)\n",
    "    model.to(device)\n",
    "\n",
    "    trainset = ImageDataset([train_files[0]])\n",
    "    valset = ImageDataset([val_files[0]])\n",
    "    train_loader, val_loader = get_dataloader(trainset, valset)\n",
    "\n",
    "    # no scheduler\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay = 5e-4)\n",
    "    best_model, best_acc_epoch_num, train_accs, train_losses, val_accs, total_time = \\\n",
    "        train_model(model, 5, train_loader, val_loader, optimizer, scheduler=None, verbose = True)\n",
    "\n",
    "    assert not isinstance(best_model, torch.nn.modules.module._IncompatibleKeys), \"Make sure you do not assign model to be model.load_state_dict().\"\n",
    "    assert best_acc_epoch_num == 5\n",
    "    assert train_accs == [0.22, 0.3352, 0.4103, 0.4582, 0.4977], train_accs\n",
    "    assert np.allclose(train_losses, [1.9889057122977676, 1.705672437977639, 1.5514380180152358, 1.4573275154563272, 1.363847457679214]), train_losses\n",
    "    # print(val_accs)\n",
    "    assert val_accs == [0.2727, 0.3604, 0.4106, 0.4442, 0.4689], val_accs\n",
    "\n",
    "    # with scheduler\n",
    "    set_seed(GLOBAL_SEED)\n",
    "    model = AlexNet(input_dim, output_dim)\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay = 5e-4)\n",
    "    scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda = lambda epoch: 0.95 * epoch)\n",
    "    best_model, best_acc_epoch_num, train_accs, train_losses, val_accs, total_time = \\\n",
    "        train_model(model, 5, train_loader, val_loader, optimizer, scheduler=scheduler, verbose = True)\n",
    "\n",
    "    assert not isinstance(best_model, torch.nn.modules.module._IncompatibleKeys), \"Make sure you do not assign model to be model.load_state_dict().\"\n",
    "    assert best_acc_epoch_num == 5, best_acc_epoch_num\n",
    "    assert train_accs == [0.098, 0.1804, 0.2667, 0.3117, 0.3212], train_accs\n",
    "    assert np.allclose(train_losses, [2.3026453917193566, 2.0861207482161794, 1.8549790860741002, 1.7612957673467649, 1.7447437754102573]), train_losses\n",
    "    assert val_accs == [0.0957, 0.2325, 0.3061, 0.299, 0.3472], val_accs\n",
    "    print('All tests passed!')\n",
    "\n",
    "test_train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rftkt1eJ7umG"
   },
   "source": [
    "## Section D: Model Training and Fine-tuning\n",
    "In this part, we will use more computational resources to train our models properly and get better accuracy. You will also get to explore the hyperparameter options to produce a trained model that meets a given performance requirement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mOICfDUh8I-r"
   },
   "source": [
    "### Question 9: Train and save model to file\n",
    "Implement the function `train_and_save_model` which, given a set of hyperparameters, trains the model on all of the $40000$ training data images and saves the trained model to a file in the `models` directory. The function takes as input a model instance of class `LogisticRegression`, `LeNet` or `AlexNet`. It also takes as input an optional parameter `filepath`, which specifies the path of the file that contains the saved model; if this parameter is not provided, the default path should be `\"models/trained_{classname}.pt\"`, for example `\"models/trained_AlexNet.pt\"`.\n",
    "\n",
    "**Notes**:\n",
    "* You will run this function on  both GPU and CPU and record the outcomes in each case. Therefore, remember to call `model.to(device)` at the beginning of the function.\n",
    "* Recall that we already initialized `full_trainset` and `full_valset` as global instances of `ImageDataset` earlier. Therefore, you only need to create the DataLoader iterables based on the given `batch_size` in this function.\n",
    "* When saving a model to a file, you only need to save its `state_dict()`, not the entire model. See the [official guide](https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-loading-model-for-inference) here for more details. \n",
    "* To get the class name of an instance variable `v`, you can call `v.__class__.__name__`.\n",
    "* If you see the following error message:\n",
    "```\n",
    "AttributeError: '_IncompatibleKeys' object has no attribute ...\n",
    "```\n",
    "you are returning the return value of `model.load_state_dict()` somewhere in an earlier question. Keep in mind that after calling `model.load_state_dict()`, you need to return the `model` itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gather": {
     "logged": 1711778994889
    },
    "id": "UO1hKp6AuURY"
   },
   "outputs": [],
   "source": [
    "def train_and_save_model(model, optimizer, batch_size=64, n_epochs=5, scheduler=None, filepath=None, verbose=False):\n",
    "    \"\"\"\n",
    "    Train a model based on the given model name, batch size, epoch number, optimizer and scheduler.\n",
    "    Then save the trained model's state_dict to a file. \n",
    "    \n",
    "    args:\n",
    "        model (nn.Module): an instance of a model class (LogisticRegression, LeNet or AlexNet)\n",
    "        optimizer (optim.Optimizer): an instance of an optimizer class in torch.optim\n",
    "    \n",
    "    kwargs:\n",
    "        batch_size (int): the minibatch size for DataLoader\n",
    "        n_epochs (int): the number of epochs to train for\n",
    "        scheduler (optim.lr_scheduler): a PyTorch scheduler that can adjust the learning rates during training\n",
    "        filepath (str): the path of the file to save the trained model to\n",
    "        verbose (bool): a flag that indicates whether print statements should be executed\n",
    "\n",
    "    return: Tuple(best_acc_model, best_acc_epoch_num, train_accs, val_accs, total_time)\n",
    "        best_acc_model (nn.Module): the model with the weight parameters that yield the best validation accuracy across all epochs\n",
    "        best_acc_epoch_num (int): the epoch number where the best validation accuracy occurs (indexed from 1)\n",
    "        train_accs (List[float]): list of average training accuracy in each epoch\n",
    "        val_accs (List[float]): list of validation accuracy in each epoch \n",
    "        total_time (float): the sum of train time and validation time across all epochs, returned from train_model\n",
    "    \"\"\"\n",
    "    model.to(device)  \n",
    "    \n",
    "   \n",
    "    train_loader = DataLoader(full_trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(full_valset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    \n",
    "   \n",
    "    best_model_state, best_epoch, train_accs, train_losses, val_accs, total_time = train_model(\n",
    "        model, n_epochs, train_loader, val_loader, optimizer, scheduler, verbose)\n",
    "    \n",
    "   \n",
    "    if filepath is None:\n",
    "        classname = model.__class__.__name__\n",
    "        filepath = f\"models/trained_{classname}.pt\"\n",
    "    os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "    \n",
    "    \n",
    "    torch.save(model.state_dict(), filepath)\n",
    "    \n",
    "   \n",
    "    if verbose:\n",
    "        print(f\"Train losses: {train_losses}\")\n",
    "    \n",
    "    \n",
    "    return model, best_epoch, train_accs, val_accs, total_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "gather": {
     "logged": 1711779086486
    },
    "id": "t9-P7MBTDM7s",
    "outputId": "3056e372-0e6c-4f00-c626-850da2810104",
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 1.8661, Train Acc = 0.3577, Val Loss = 1.8524, Val Acc = 0.3607\n",
      "Epoch 2: Train Loss = 1.7927, Train Acc = 0.3861, Val Loss = 1.8311, Val Acc = 0.3786\n",
      "Epoch 3: Train Loss = 1.7676, Train Acc = 0.3956, Val Loss = 1.8982, Val Acc = 0.3712\n",
      "Epoch 4: Train Loss = 1.7570, Train Acc = 0.4000, Val Loss = 1.8134, Val Acc = 0.3844\n",
      "Epoch 5: Train Loss = 1.7461, Train Acc = 0.4034, Val Loss = 1.8463, Val Acc = 0.3712\n",
      "Train losses: [1.8660555881500245, 1.7926853664398192, 1.7676213230133058, 1.7569928256988525, 1.7461212633132934]\n",
      "Epoch 1: Train Loss = 1.7061, Train Acc = 0.3740, Val Loss = 1.5053, Val Acc = 0.4528\n",
      "Epoch 2: Train Loss = 1.4116, Train Acc = 0.4889, Val Loss = 1.3540, Val Acc = 0.5169\n",
      "Epoch 3: Train Loss = 1.2969, Train Acc = 0.5337, Val Loss = 1.2741, Val Acc = 0.5374\n",
      "Epoch 4: Train Loss = 1.2100, Train Acc = 0.5667, Val Loss = 1.2079, Val Acc = 0.5744\n",
      "Epoch 5: Train Loss = 1.1424, Train Acc = 0.5949, Val Loss = 1.1716, Val Acc = 0.5873\n",
      "Train losses: [1.706101128768921, 1.4116289947509766, 1.2968819150924682, 1.2099555132865907, 1.1423828713417052]\n",
      "Epoch 1: Train Loss = 1.8604, Train Acc = 0.2602, Val Loss = 1.5984, Val Acc = 0.3832\n",
      "Epoch 2: Train Loss = 1.4715, Train Acc = 0.4423, Val Loss = 1.3524, Val Acc = 0.5091\n",
      "Epoch 3: Train Loss = 1.2765, Train Acc = 0.5327, Val Loss = 1.1635, Val Acc = 0.5814\n",
      "Epoch 4: Train Loss = 1.1483, Train Acc = 0.5878, Val Loss = 1.1443, Val Acc = 0.6002\n",
      "Epoch 5: Train Loss = 1.0529, Train Acc = 0.6261, Val Loss = 1.1142, Val Acc = 0.6095\n",
      "Train losses: [1.8603876827239991, 1.4715276823043824, 1.2764976123809815, 1.1483496306419372, 1.0528730136871338]\n",
      "All tests passed!\n",
      "Logistic regression on GPU:\n",
      "Best model's train acc: 0.4, Best model's val acc: 0.3844, Training + Validation time: 25.885958671569824\n",
      "LeNet on GPU:\n",
      "Best model's train acc: 0.5949, Best model's val acc: 0.5873, Training + Validation time: 25.956050157546997\n",
      "AlexNet on GPU:\n",
      "Best model's train acc: 0.626075, Best model's val acc: 0.6095, Training + Validation time: 35.313313484191895\n"
     ]
    }
   ],
   "source": [
    "def test_train_and_save_model_gpu():\n",
    "    # train_and_save_model_gpu should be run on GPU in this test function\n",
    "    assert device.type == \"cuda\"\n",
    "\n",
    "    # logistic regression performance\n",
    "    set_seed(GLOBAL_SEED)\n",
    "    model = LogisticRegression(input_dim, output_dim)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay = 5e-4)\n",
    "    _, logistic_best_epoch, logistic_train_accs, logistic_val_accs, logistic_time = \\\n",
    "        train_and_save_model(model, optimizer, n_epochs = 5, verbose = True)\n",
    "    assert logistic_best_epoch == 4, logistic_best_epoch\n",
    "    assert logistic_train_accs ==  [0.357725, 0.38605, 0.39555, 0.4, 0.4034], logistic_train_accs\n",
    "    assert logistic_val_accs == [0.3607, 0.3786, 0.3712, 0.3844, 0.3712], logistic_val_accs\n",
    "    assert os.path.isfile(\"models/trained_LogisticRegression.pt\")\n",
    "\n",
    "    # LeNet performance\n",
    "    set_seed(GLOBAL_SEED)\n",
    "    model = LeNet(input_dim, output_dim)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay = 5e-4)\n",
    "    _, lenet_best_epoch, lenet_train_accs, lenet_val_accs, lenet_time = \\\n",
    "        train_and_save_model(model, optimizer, n_epochs = 5, verbose = True)\n",
    "    assert lenet_best_epoch == 5, lenet_best_epoch\n",
    "    assert lenet_train_accs == [0.37395, 0.48885, 0.533725, 0.5667, 0.5949], lenet_train_accs\n",
    "    assert lenet_val_accs == [0.4528, 0.5169, 0.5374, 0.5744, 0.5873], lenet_val_accs\n",
    "    assert os.path.isfile(\"models/trained_LeNet.pt\")\n",
    "\n",
    "    # AlexNet performance\n",
    "    set_seed(GLOBAL_SEED)\n",
    "    model = AlexNet(input_dim, output_dim)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay = 5e-4)\n",
    "    _, alexnet_best_epoch, alexnet_train_accs, alexnet_val_accs, alexnet_time = \\\n",
    "         train_and_save_model(model, optimizer, n_epochs = 5, verbose = True)\n",
    "    assert alexnet_best_epoch == 5, alexnet_best_epoch\n",
    "    assert alexnet_train_accs == [0.260175, 0.4423, 0.532725, 0.587825, 0.626075], alexnet_train_accs\n",
    "    assert alexnet_val_accs == [0.3832, 0.5091, 0.5814, 0.6002, 0.6095], alexnet_val_accs\n",
    "    assert os.path.isfile(\"models/trained_AlexNet.pt\")\n",
    "\n",
    "    print(\"All tests passed!\")\n",
    "    print(\"Logistic regression on GPU:\")\n",
    "    print(\"Best model's train acc: {}, Best model's val acc: {}, Training + Validation time: {}\".format(\n",
    "        logistic_train_accs[logistic_best_epoch-1], logistic_val_accs[logistic_best_epoch-1], logistic_time\n",
    "    ))\n",
    "    print(\"LeNet on GPU:\")\n",
    "    print(\"Best model's train acc: {}, Best model's val acc: {}, Training + Validation time: {}\".format(\n",
    "        lenet_train_accs[lenet_best_epoch-1], lenet_val_accs[lenet_best_epoch-1], lenet_time\n",
    "    ))\n",
    "    print(\"AlexNet on GPU:\")\n",
    "    print(\"Best model's train acc: {}, Best model's val acc: {}, Training + Validation time: {}\".format(\n",
    "        alexnet_train_accs[alexnet_best_epoch-1], alexnet_val_accs[alexnet_best_epoch-1], alexnet_time\n",
    "    ))\n",
    "\n",
    "test_train_and_save_model_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SgRsEBUlyQrl"
   },
   "source": [
    "You should now open `report.md` and record the time and accuracy of each of our 3 models; this information is printed after the message \"All tests passed!\" in `test_train_and_save_model_gpu`.\n",
    "\n",
    "Next, let's also see how long the same training process would take on CPU. Run the following function and record each model's performance and time taken in `report.md`. Note that this cell may take about half an hour to run and it is **not required** for subsequent questions, so feel free to skip it for now and return later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gather": {
     "logged": 1711778589480
    },
    "id": "aNyaFr2-zI-R",
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 1.8661, Train Acc = 0.3577, Val Loss = 1.8524, Val Acc = 0.3607\n",
      "Epoch 2: Train Loss = 1.7927, Train Acc = 0.3861, Val Loss = 1.8311, Val Acc = 0.3786\n",
      "Epoch 3: Train Loss = 1.7676, Train Acc = 0.3956, Val Loss = 1.8982, Val Acc = 0.3712\n",
      "Epoch 4: Train Loss = 1.7570, Train Acc = 0.4000, Val Loss = 1.8134, Val Acc = 0.3844\n",
      "Epoch 5: Train Loss = 1.7461, Train Acc = 0.4034, Val Loss = 1.8463, Val Acc = 0.3712\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 42\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAlexNet on CPU:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest model\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms train acc: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, Best model\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms val acc: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, Training + Validation time: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     39\u001b[0m         alexnet_train_accs[alexnet_best_epoch\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], alexnet_val_accs[alexnet_best_epoch\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], alexnet_time\n\u001b[1;32m     40\u001b[0m     ))\n\u001b[0;32m---> 42\u001b[0m \u001b[43mtest_train_and_save_model_CPU\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[96], line 13\u001b[0m, in \u001b[0;36mtest_train_and_save_model_CPU\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m LogisticRegression(input_dim, output_dim)\n\u001b[1;32m     11\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, weight_decay \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5e-4\u001b[39m)\n\u001b[1;32m     12\u001b[0m _, logistic_best_epoch, logistic_train_accs, logistic_val_accs, logistic_time \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m---> 13\u001b[0m     \u001b[43mtrain_and_save_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLogisticRegression_CPU.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# LeNet performance\u001b[39;00m\n\u001b[1;32m     16\u001b[0m set_seed(GLOBAL_SEED)\n",
      "Cell \u001b[0;32mIn[94], line 38\u001b[0m, in \u001b[0;36mtrain_and_save_model\u001b[0;34m(model, optimizer, batch_size, n_epochs, scheduler, filepath, verbose)\u001b[0m\n\u001b[1;32m     36\u001b[0m     classname \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[1;32m     37\u001b[0m     filepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/trained_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclassname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 38\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdirname\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(best_model_state, filepath)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/os.py:223\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 223\u001b[0m     \u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exist_ok \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39misdir(name):\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: ''"
     ]
    }
   ],
   "source": [
    "def test_train_and_save_model_CPU():\n",
    "    global device\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "    # train_and_save_model_cpu should be run on CPU in this test function\n",
    "    assert device.type == \"cpu\"\n",
    "\n",
    "    # logistic regression performance\n",
    "    set_seed(GLOBAL_SEED)\n",
    "    model = LogisticRegression(input_dim, output_dim)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay = 5e-4)\n",
    "    _, logistic_best_epoch, logistic_train_accs, logistic_val_accs, logistic_time = \\\n",
    "        train_and_save_model(model, optimizer, n_epochs = 5, filepath = \"LogisticRegression_CPU.pt\", verbose = True)\n",
    "\n",
    "    # LeNet performance\n",
    "    set_seed(GLOBAL_SEED)\n",
    "    model = LeNet(input_dim, output_dim)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay = 5e-4)\n",
    "    _, lenet_best_epoch, lenet_train_accs, lenet_val_accs, lenet_time = \\\n",
    "        train_and_save_model(model, optimizer, n_epochs = 5, filepath = \"LeNet_CPU.pt\", verbose = True)\n",
    "\n",
    "    # AlexNet performance\n",
    "    set_seed(GLOBAL_SEED)\n",
    "    model = AlexNet(input_dim, output_dim)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay = 5e-4)\n",
    "    _, alexnet_best_epoch, alexnet_train_accs, alexnet_val_accs, alexnet_time = \\\n",
    "         train_and_save_model(model, optimizer, n_epochs = 5, filepath = \"AlexNet_CPU.pt\", verbose = True)\n",
    "\n",
    "    print(\"Logistic regression on CPU:\")\n",
    "    print(\"Best model's train acc: {}, Best model's val acc: {}, Training + Validation time: {}\".format(\n",
    "        logistic_train_accs[logistic_best_epoch-1], logistic_val_accs[logistic_best_epoch-1], logistic_time\n",
    "    ))\n",
    "    print(\"LeNet on CPU:\")\n",
    "    print(\"Best model's train acc: {}, Best model's val acc: {}, Training + Validation time: {}\".format(\n",
    "        lenet_train_accs[lenet_best_epoch-1], lenet_val_accs[lenet_best_epoch-1], lenet_time\n",
    "    ))\n",
    "    print(\"AlexNet on CPU:\")\n",
    "    print(\"Best model's train acc: {}, Best model's val acc: {}, Training + Validation time: {}\".format(\n",
    "        alexnet_train_accs[alexnet_best_epoch-1], alexnet_val_accs[alexnet_best_epoch-1], alexnet_time\n",
    "    ))\n",
    "\n",
    "test_train_and_save_model_CPU()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WuewxhmGH4qc"
   },
   "source": [
    "Now let's switch back to using GPU for our next task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "gather": {
     "logged": 1711547143302
    },
    "id": "p63f-wh-H7ew",
    "outputId": "0efcf8b5-d0c7-402a-d8b7-3ffffabea692"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END OF PART 1\n",
    "You have finished part 1 of the project. To submit this part, open the terminal in Azure ML Studio and run the following commands:\n",
    "\n",
    "```\n",
    "export SUBMISSION_USERNAME=<Sail() username>\n",
    "export SUBMISSION_PASSWORD=<Sail() password>\n",
    "./submitter_part1\n",
    "```\n",
    "\n",
    "Make sure you get full score for every question in Part 1 before continuing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x55jwwH3AAwQ"
   },
   "source": [
    "### Question 10: Fine-tune your own model\n",
    "Note that so far we have only run the three models on a fixed set of hyperparameters with very few epochs, and so unsurprisingly, the model performances are fairly mediocre. However, with a proper setting of hyperparameters, optimizer and (possibly) scheduler, our models can achieve much higher training and validation accuracy.\n",
    "\n",
    "Now it is time for your own exploration! We have provided a template function `fine_tune_model` for you, where you can specify the model class and relevant hyparameter choices. After filling in these values, run `fine_tune_model_test` to check if your model choice meets the performance criteria: we require a training accuracy of **at least 80%** and a validation accuracy of **at least 70%**.\n",
    "\n",
    "**Notes**:\n",
    "* You can choose to fine-tune either a LogisticRegression, LeNet or AlexNet model (only **one** fine-tuned model is needed). Do not modify the class implementations in Q3/Q4/Q5, or the data preprocessing steps in Q1. Instead, only fill in the variables that are currently set to `None` in `fine_tune_model` (but you can leave `scheduler` as `None`; using scheduler is not required to meet the performance requirement).\n",
    "* We recommend experimenting with the batch size first. Increasing the batch size alone can already lead to substantial model improvement in this case.\n",
    "* When `fine_tune_model` finishes running, it will also save the trained model to a file with the name `tuned_{classname}_{index}.pt`, for example `tuned_AlexNet_5.pt`. The index will be incremented automatically depending on how many tuned models of the same class are already present (this is to prevent a new model from overwriting any previously saved model file). We have provided the code to implement this functionality for you.\n",
    "* The Sail() testing data (which your model needs to get at least 70% prediction accuracy on) is not the same as the validation data provided here. However, your model performance on the validation data and on this secret test data should be close. If you pass the local test but not the autograder test, try training for a few more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gather": {
     "logged": 1711547143319
    },
    "id": "55-xI0I9upSY"
   },
   "outputs": [],
   "source": [
    "def fine_tune_model():\n",
    "    \"\"\"\n",
    "    Fine tune a model instance of LogisticRegression or LeNet or AlexNet.\n",
    "\n",
    "    return: Tuple(best_acc_model, best_acc_epoch_num, train_accs, val_accs, total_time)\n",
    "        best_acc_model (nn.Module): the model state with the weight parameters that yield the best validation accuracy across all epochs\n",
    "        best_acc_epoch_num (int): the epoch number where the best validation accuracy occurs (indexed from 1)\n",
    "        train_accs (List[float]): list of average training accuracy in each epoch\n",
    "        val_accs (List[float]): list of validation accuracy in each epoch\n",
    "        total_time (float): the sum of train time and validation time across all epochs, returned from train_and_save_model\n",
    "    \"\"\" \n",
    "    # initialize your model here\n",
    "    model = None\n",
    "    model.to(device)\n",
    "    \n",
    "    # specify your optimizer and scheduler here\n",
    "    optimizer = None\n",
    "    scheduler = None # optional, can leave as None\n",
    "    \n",
    "    # specify your hyperparameters here\n",
    "    batch_size = None\n",
    "    n_epochs = None\n",
    "    \n",
    "    # do not modify the remaining code\n",
    "    classname = model.__class__.__name__\n",
    "    index = 0\n",
    "    while os.path.isfile(f\"tuned_{classname}_{index}.pt\"):\n",
    "        index += 1\n",
    "    return train_and_save_model(\n",
    "        model, optimizer, batch_size, n_epochs,\n",
    "        scheduler, f\"tuned_{classname}_{index}.pt\", verbose = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "gather": {
     "logged": 1711547143338
    },
    "id": "LVV2LyvaBNHf",
    "outputId": "597ba67c-0b0e-4007-b7bb-64066e0ba7d1",
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "def test_fine_tune_model():\n",
    "    set_seed(GLOBAL_SEED)\n",
    "    model, best_acc_epoch_num, train_accs, val_accs, total_time = fine_tune_model()\n",
    "\n",
    "    print(\"Best model's train acc: {}, Best model's val acc: {}, Training + Validation time: {}\".format(\n",
    "        train_accs[best_acc_epoch_num-1], val_accs[best_acc_epoch_num-1], total_time\n",
    "    ))\n",
    "\n",
    "    # check performance requirement\n",
    "    assert train_accs[best_acc_epoch_num-1] >= 0.79, train_accs[best_acc_epoch_num-1]\n",
    "    assert val_accs[best_acc_epoch_num-1] >= 0.70, val_accs[best_acc_epoch_num-1]\n",
    "\n",
    "    # check that network structures are not changed\n",
    "    n_params = count_parameters(model)\n",
    "    if isinstance(model, LogisticRegression):\n",
    "        assert n_params == 30730\n",
    "    elif isinstance(model, LeNet):\n",
    "        assert n_params == 62006\n",
    "    elif isinstance(model, AlexNet):\n",
    "        assert n_params == 10655562\n",
    "    else:\n",
    "        assert False, \"Unrecognized model class\"\n",
    "\n",
    "    print(\"All tests passed! Make sure to run the code cell below before submitting to Sail().\")\n",
    "\n",
    "test_fine_tune_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z0HwGzQJOlXi"
   },
   "source": [
    "To submit your tuned model for Q10, enter the name of the file that contains your **best fine tuned model** to the variable `tuned_model_file` below, and execute the code cell. This will clean the model file name and make a copy of it in the `models` directory. Then you can run the `submitter` executable; it will automatically pick up all the files in your `models` directory to submit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1711547143356
    },
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "# enter the name of your fine tuned model file below\n",
    "tuned_model_file = None\n",
    "\n",
    "if tuned_model_file:\n",
    "    # remove trailing index from filename\n",
    "    renamed_model_file = re.sub(\"_\\d+\", \"\", tuned_model_file)\n",
    "    assert renamed_model_file in [\"tuned_LogisticRegression.pt\", \"tuned_LeNet.pt\", \"tuned_AlexNet.pt\"]\n",
    "\n",
    "    # copy the file to the models directory\n",
    "    os.system(f\"cp {tuned_model_file} models/{renamed_model_file}\")\n",
    "\n",
    "    # check that the models directory only has four model files\n",
    "    assert len([file for file in os.listdir(\"models\") if file.endswith(\".pt\")]) == 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes our model training section! You should now have filled in all of the required details in `report.md`. Look at the differences in runtime and in performance between CPU and GPU; what do you notice? How much improvement does your fine tuned model provide, compared to the 3 base models training on 5 epochs? What is the cost of this improvement, in terms of runtime and cloud budget? For reference, a `Standard_D3_V2` CPU costs \\$0.293/hour, while a `Standard_NC6` GPU costs \\$0.90/hour.\n",
    "\n",
    "We often hear about the runtime vs space tradeoff in computer science, or bias vs variance tradeoff in machine learning. In a practical business setting, an equally important consideration is the cost vs performance tradeoff. Depending on your goals and constraints, you will need to decide on when it is suitable to investigate more budget into performance improvement, and whether the added improvement is worth the cost.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Ux7xG8M8_4B"
   },
   "source": [
    "## Section E: Deployment \n",
    "In the final part of Project 6, you will deploy your trained models to an API endpoint, so that if other people need to use your models' inferences, they can simply send an HTTP request to your API.\n",
    "\n",
    "**Question 11 can still be completed on CoLab, while Question 12 should be completed on a DS3_v2 CPU Compute on Azure Machine Learning Studio.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bAWz-7a3BUcZ"
   },
   "source": [
    "### Question 11: Construct JSON responses to input data\n",
    "Before setting up the deployment, let's think about what our inputs and outputs should look like. Each incoming HTTP POST request will contain an image matrix in the same format as CIFAR-10 images. We also have a list of 4 models listed above. For each model, we want to return (1) its predicted label for the input image, and (2) the probability that it thinks it is correct.\n",
    "\n",
    "To get these outputs, recall that each of our models has a 10-node linear output layer, i.e., the output from the forward pass is a tensor of 10 scalars $o_1, o_2, \\ldots, o_{10}$. We can then use the softmax function to compute the probability that our model thinks label $i$ is correct:\n",
    "\n",
    "$$P(y = i \\mid x) = \\frac{\\exp(o_i)}{\\sum_{j=1}^{10} \\exp(o_j)}.$$\n",
    "\n",
    "and the final predicted label is the one that has the highest probability: $\\hat y = \\underset{i}{\\operatorname{argmax}} P(y = i \\mid x).$\n",
    "\n",
    "Because we have multiple models, we would like the return format to be a dictionary as follows:\n",
    "\n",
    "```python\n",
    "{\n",
    "    \"model1\" : {\"label\" : \"car\", \"probability\" : \"0.12\" },\n",
    "    \"model2\" : {\"label\" : \"truck\", \"probability\" : \"0.34\" },\n",
    "    ...\n",
    "}\n",
    "```\n",
    "where `\"model1\", \"model2\"` are the provided model names.\n",
    "\n",
    "Implement the function `get_predictions` that takes as input (1) an input image data (a Numpy array), and (2) a mapping from model name to model instance. It then converts the input data to a `FloatTensor`, feeds the data to each model, and outputs a dictionary with the format above, where the keys are all the model names from the input mapping, and the probability values are **rounded to 2 decimal digits**.\n",
    "\n",
    "**Notes**:\n",
    "* Remember to call `model.eval()` and `with torch.no_grad()` to save space and computation time.\n",
    "* You should convert the input `data` to a tensor by calling `torch.FloatTensor` and send it to `device`, so that this function can work on both GPU and CPU (later on we will only do the deployment on CPU).\n",
    "* To compute $P(y = i \\mid x)$ you can create a PyTorch model with a single `nn.Softmax` layer.\n",
    "* To get consistent output with the autograder, use `str(round(p, 2))` for the probability values in the returned dictionary.\n",
    "* Once you have identified the index of the predicted label $\\hat y$, use the `classes` list we provide at the beginning to retrieve the actual label. As a reminder, here is the definition of `classes`:\n",
    "\n",
    "```python\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "```\n",
    "so $\\hat y = 0$ corresponds to the label `plane`, $\\hat y = 1$ to `car`, and so on.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gather": {
     "logged": 1711547143372
    },
    "id": "1od3DKPy7eBT"
   },
   "outputs": [],
   "source": [
    "def get_predictions(data, model_mapping):\n",
    "    \"\"\"\n",
    "    Generate the predicted label of each model in the provided model mapping for an input image.\n",
    "\n",
    "    args:\n",
    "        data (np.array) : a single image data with shape (1, 3, 32, 32)\n",
    "        model_mapping (Dict[str, nn.Module]) : a mapping between a string model name and a model object,\n",
    "            which is an instance of either LogisticRegression, LeNet or AlexNet\n",
    "    \n",
    "    return:\n",
    "        Dict[str, Dict[str, str]]: a dictionary where each key is a model name from model_mapping, and each value \n",
    "            is an inner dictionary with format {\"label\" : str, \"probability\" : str}\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "gather": {
     "logged": 1711547143389
    },
    "id": "qGDZZ94FN-RF",
    "outputId": "3826761a-7d82-4658-88d3-1910c6e6b1d4",
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "def test_get_predictions():\n",
    "    # load 2 models into model_mapping\n",
    "    logit = LogisticRegression(input_dim, output_dim).to(device)\n",
    "    lenet = LeNet(input_dim, output_dim).to(device)\n",
    "    logit.load_state_dict(torch.load(\"models/trained_LogisticRegression.pt\", map_location = device))\n",
    "    lenet.load_state_dict(torch.load(\"models/trained_LeNet.pt\", map_location = device))\n",
    "    model_mapping = {\"LogisticRegression\" : logit, \"LeNet\" : lenet}\n",
    "    \n",
    "    data = full_valset[0][0].reshape(1, 3, 32, 32).numpy()\n",
    "    predictions = get_predictions(data, model_mapping)\n",
    "    assert predictions == {\n",
    "        \"LogisticRegression\" : {\"label\" : \"plane\", \"probability\" : \"0.32\"},\n",
    "        \"LeNet\" : {\"label\" : \"car\", \"probability\" : \"0.99\"}\n",
    "    }, predictions\n",
    "    print(\"All tests passed!\")\n",
    "\n",
    "test_get_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C3ceGOC4ABhf"
   },
   "source": [
    "### Question 12: Deploy model to public API\n",
    "Now let's begin the environment setup for model deployment. First, we import the relevant Azure SDK packages. These should already be pre-installed when you run the notebook on Azure Studio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gather": {
     "logged": 1711547143406
    },
    "id": "HW2lMb3pnd54",
    "outputId": "fe3240f0-e0b6-4f80-995a-2ad302cf97a3",
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.webservice import LocalWebservice, AciWebservice\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the steps in the [Model Deployment primer notebook](https://nbviewer.jupyter.org/url/clouddatascience.blob.core.windows.net/primers/machine-learning-azure-primer/azure_model_deployment_primer.ipynb#1.-Model-training-and-saving) to deploy all of the model files in your `models` directory to a public endpoint (all four models are deployed together in one endpoint). We will provide some brief reminders for each deployment step as follows, Note that all of the deployment-related code cells should have the tag `excluded_from_script`, as the autograder does not run your deployment code. It will only send requests to your endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ComJ1d0HAIKR"
   },
   "source": [
    "**Step 1: Initialize workspace with `Workspace.from_config()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gather": {
     "logged": 1711547143422
    },
    "id": "iS-I_8D5ALiH",
    "outputId": "75c0eee6-46ae-49b5-b9a2-b8b5a9c523ae",
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u3xRd__LANl8"
   },
   "source": [
    "**Step 2: Register the model with `Model.register()`**\n",
    "\n",
    "Here, you have one of two options:\n",
    "\n",
    "1. You could specify the `model_path` value as `\"models\"` to point to the `./models` directory, which has all of your `.pt` model files from earlier questions. \n",
    "2. You can register each model separately, following what the primer does.\n",
    "\n",
    "\n",
    "The `model_name` and `description` parameters are up to you. \n",
    "\n",
    "**Note:**\n",
    "* The `model_name` parameter is just used in step 3 to get the location of the model / the model directory. It's not necessarily pointing to one model in particular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1711547143437
    },
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lnM15EyqDQ3a"
   },
   "source": [
    "**Step 3: Create scoring script and API endpoint**\n",
    "\n",
    "Now comes the main deployment task: you need to specify how the models are initialized and how to process the input data. For this project, you can assume that each incoming POST request only contains data about a single $3 \\times 32 \\times 32$ image to classify, and the JSON content is formatted as follows:\n",
    "\n",
    "```\n",
    "input_data = {\n",
    "    \"image\" : [0.1, 0.7, 0.3, ...]\n",
    "}\n",
    "```\n",
    "where the key `\"image\"` maps to a 3072-element Python list which represents the input image being flattened.\n",
    "\n",
    "\n",
    "The basic structure will be as follows:\n",
    "\n",
    "* You should maintain a global dictionary `model_mapping` that maps the model file names to their corresponding loaded models. For example it would map the string `\"trained_LeNet.pt\"` to an instance of the class `LeNet` that is loaded from this file.\n",
    "* The `init()` function will initialize `model_mapping`. Use the `<model_name>` parameter(s) you specified in Step (2) to either get the directory where all of the models are stored, or the path of each file.\n",
    "* The `run()` function retrieves the flattened image list, then reshapes and passes it to `get_predictions` to get the predicted label. We have provided the implementation of `run`, but you will also need to **copy** the implementation code of `get_predictions` from Q11 to this cell.\n",
    "* `LogisticRegression`: copy your implementation of the class `LogisticRegression` from Q3.\n",
    "* `LeNet`: copy your implementation of the class `LeNet` from Q4.\n",
    "* `AlexNet`: copy your implementation of the class `AlexNet` from Q5.\n",
    "\n",
    "**Notes**:\n",
    "* Recall that to modify a global variable inside a function in Python, you need to use the `global` keyword.\n",
    "* Check the local test of Q11 for how to properly load a PyTorch model from file. Also see the [PyTorch documentation](https://pytorch.org/tutorials/beginner/saving_loading_models.html) for more details.\n",
    "* Copying here means you should copy and paste the actual implementation code.\n",
    "* `Model.get_model_path('<model_name>')` will return a string path poining to what you registered.\n",
    "    * If you registered the full `models` directory, you can join `Model.get_model_path('<model_name>')` with the string `\"trained_LeNet.pt\"` to get the path to the LeNet model file, which you can then input to `torch.load` to load this model.\n",
    "    * If you registered each model separately, this will just return the path to the stored state dict.\n",
    "* `Model.get_model_path('<model_name>')` only works in the deployment environment. If you want to test it locally on your notebook, you can specify an additional parameter: `Model.get_model_path('<model_name>', _workspace = <your workspace variable from Step 1>)`. But this parameter should not be present in `scoring.py`.\n",
    "* Azure may automatically add some metadata files to the deployment directory. As you iterate through the files in `Model.get_model_path('<model_name>')`, make sure to check that the file name ends in `.pt` before using it to load a PyTorch model (this only applies if you registered the entire `models` directory).\n",
    "* Make sure you first try running `score.py` before deployment to check for errors. One possible way to run the file is to hard-code `path_to_model` inside the `init` function, call `init()` at the end of the `score.py`, and run the file from the Azure terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WPCP_SnX9dH4",
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "%%writefile ./score.py\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from azureml.core.model import Model\n",
    "\n",
    "# do not modify this code\n",
    "device = torch.device(\"cpu\")\n",
    "input_dim, output_dim = (3, 32, 32), 10\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "model_mapping = {}\n",
    "\n",
    "\n",
    "#########################################\n",
    "#### Primary functions for score.py #####\n",
    "#########################################\n",
    "\n",
    "def init():\n",
    "    \"\"\"\n",
    "    Load registered models from the directory Model.get_model_path('<model_name>')\n",
    "    and initialize model_mapping as a mapping from model file name to loaded model.\n",
    "\n",
    "    Note: <model_name> here just refers to the name you registered the model in step 2.\n",
    "    \n",
    "    When this function finishes, model_mapping should look like\n",
    "    \n",
    "    {\n",
    "        \"trained_LogisticRegression.pt\" : <loaded model from trained_LogisicRegression.pt>,\n",
    "        \"trained_LeNet.pt\" : <loaded model from trained_LeNet.pt>,\n",
    "        \"trained_AlexNet.pt\" : <loaded model from trained_AlexNet.pt>,\n",
    "        \"tuned_{classname}.pt\" : <loaded model from tuned_{classname}.pt>\n",
    "    }\n",
    "    \n",
    "    Here classname should be either \"LogisticRegression\", \"LeNet\" or \"AlexNet\",\n",
    "    depending on which model you fine-tuned earlier.\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def run(input_data):\n",
    "    \"\"\"\n",
    "    Get the label prediction and associated probability value of an input image\n",
    "    from each model in model_mapping.\n",
    "    \n",
    "    args:\n",
    "        data (Dict[str, List[float]]):\n",
    "            the input JSON, which maps the key \"image\" to a flattened image (a 3072-element Python list)\n",
    "    \n",
    "    return:\n",
    "        Dict[str, Dict[str, str]]: a dictionary where each key is a model name from model_mapping,\n",
    "            and each value is an inner dictionary with format {\"label\" : str, \"probability\" : str}\n",
    "    \n",
    "    \"\"\"\n",
    "    # do not modify this code\n",
    "    input_json = json.loads(input_data)\n",
    "    image_data = np.asarray(input_json[\"image\"]).reshape(1, 3, 32, 32)\n",
    "    return get_predictions(image_data, model_mapping)\n",
    "\n",
    "\n",
    "def get_predictions(data, model_mapping):\n",
    "    \"\"\"\n",
    "    Copy the code from get_predictions (Q11) here\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "#########################################\n",
    "## Copy of model class implementations ##\n",
    "#########################################\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        \"\"\"\n",
    "        Copy the code from __init__ in LogisticRegression here\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Copy the code from forward in LogisticRegression here\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        \"\"\"\n",
    "        Copy the code from __init__ in LeNet here\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Copy the code from forward in LeNet here\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        \"\"\"\n",
    "        Copy the code from __init__ in AlexNet here\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Copy the code from forward in AlexNet here\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MX5bxnkeZAFI"
   },
   "source": [
    "Now check that the content of `score.py` is as you expect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "!cat score.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uehgIMl3EJ-Q"
   },
   "source": [
    "**Step 4: Create environment file**\n",
    "\n",
    "Now you will need to create an environment file (`myenv.yml`) that specifies all of the scoring script's package dependencies. This file is used to ensure that all of those dependencies are installed in the Docker image by Azure ML. The `pip_packages` parameter value should be the following list:\n",
    "\n",
    "```python\n",
    "['azureml-defaults', 'torch~=2.0.1']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1711547143459
    },
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "## your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5: Deploy to Local service**\n",
    "\n",
    "Follow the steps in the primer to create an `Environment`, an `InferenceConfig`, a `LocalWebservice`, a `Model.deploy` object, and call `wait_for_deployment` on it. Note that if you registered each of the 4 models individually, you need to construct a list of all the 4 model registrations and input it to the `models` parameter when calling `Model.deploy`.\n",
    "\n",
    "\n",
    "This code may take about 25-30 minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1711547143473
    },
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "## replace the None values with your code\n",
    "myenv = None\n",
    "inference_config = None\n",
    "local_deployment_config = None\n",
    "local_service = None\n",
    "local_service.wait_for_deployment(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you see an error message \"Error: Container has crashed. Did your init method fail?\", refer to Section 2.3.3 in the [deployment primer](https://nbviewer.jupyter.org/url/clouddatascience.blob.core.windows.net/primers/machine-learning-azure-primer/azure_model_deployment_primer.ipynb) for instructions on debugging and updating your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6: Test the local service**\n",
    "\n",
    "We provide some helper functions to construct the input JSON, as well as a local test function to check the output of your local service. For an image from the CIFAR-10 dataset, we simply flatten its matrix data and send it along the request. For an external image, there is an extra step of converting it to a format consistent with CIFAR-10 images (with shape $3 \\times 32 \\times 32$ and normalized values).\n",
    "\n",
    "**Notes**:\n",
    "* If your model probabilities change when you run this local test multiple times, make sure you have called `model.eval()` and `with torch.no_grad()` in your `get_predictions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1711547143487
    },
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    \"\"\"Preprocess external input image to have the same format as a CIFAR-10 image.\"\"\"\n",
    "    data_transforms = transforms.Compose([\n",
    "        transforms.Resize(32),\n",
    "        transforms.CenterCrop(32),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "    image = data_transforms(image).double()\n",
    "    image = image.clone().detach()\n",
    "    image = image.unsqueeze(0)\n",
    "    return image.numpy()\n",
    "\n",
    "def show_cifar_image(image):\n",
    "    image = image / 2 + 0.5\n",
    "    npimg = image.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1711547143505
    },
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "def test_local_deployment():\n",
    "    # cifar-10 image\n",
    "    cifar_img, label = full_valset[3]\n",
    "    show_cifar_image(cifar_img)\n",
    "    print(\"Ground truth label: \", classes[label])\n",
    "    input_json = json.dumps({\n",
    "        \"image\" : cifar_img.unsqueeze(0).numpy().tolist()\n",
    "    })\n",
    "    content = local_service.run(bytes(input_json, encoding = \"utf-8\"))\n",
    "    print(content)\n",
    "    assert content['trained_AlexNet.pt'] == {'label': 'car', 'probability': '0.89'}, content['trained_AlexNet.pt']\n",
    "    assert content['trained_LeNet.pt'] == {'label': 'car', 'probability': '0.91'}, content['trained_LeNet.pt']\n",
    "    assert content['trained_LogisticRegression.pt'] == {'label': 'car', 'probability': '0.62'}, content['trained_LogisticRegression.pt']\n",
    "    print(\"Fine tuned model's prediction:\", [pred for name, pred in content.items() if 'tuned' in name][0])\n",
    "\n",
    "    # external image\n",
    "    external_img = Image.open('test_img.jpg')\n",
    "    plt.imshow(external_img)\n",
    "    print(\"Groud truth label: bird\")\n",
    "    external_img_formatted = preprocess(external_img)\n",
    "    input_json = json.dumps({\n",
    "        \"image\" : external_img_formatted.tolist()\n",
    "    })\n",
    "    content = local_service.run(bytes(input_json, encoding = \"utf-8\"))\n",
    "    print(content)\n",
    "    assert content['trained_AlexNet.pt'] == {'label': 'frog', 'probability': '0.52'}, content['trained_AlexNet.pt']\n",
    "    assert content['trained_LeNet.pt'] == {'label': 'car', 'probability': '0.24'}, content['trained_LeNet.pt']\n",
    "    assert content['trained_LogisticRegression.pt'] == {'label': 'car', 'probability': '0.82'}, content['trained_LogisticRegression.pt']\n",
    "    print(\"Fine tuned model's prediction:\", [pred for name, pred in content.items() if 'tuned' in name][0])\n",
    "    \n",
    "    print(\"All tests passed!\")\n",
    "\n",
    "test_local_deployment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XZeEx-gNE67h"
   },
   "source": [
    "**Step 6: Deploy to ACI container**\n",
    "\n",
    "Now that your local service has worked properly, the last step is to deploy it to a pulic endpoint. Follow the steps in the primer to create an `AciWebService` and a new `Model.deploy` object, then call `wait_for_deployment` on it. This code should take about 20 minutes to run. If it takes longer, you should consult the \"Monitoring public deployment\" section in the primer to diagnose the issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1711547143525
    },
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "## replace the None values with your code\n",
    "aci_deployment_config = None\n",
    "aci_service = None\n",
    "aci_service.wait_for_deployment(True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zQJxY5XJJPBI"
   },
   "source": [
    "When the deployment succeeds, you will see the output as\n",
    "\n",
    "```\n",
    "Succeeded\n",
    "ACI service creation operation finished, operation \"Succeeded\"\n",
    "Healthy\n",
    "```\n",
    "\n",
    "If this cell runs for more than 30 minutes, something is wrong with `score.py` so you should:\n",
    "\n",
    "1. Stop the code execution\n",
    "1. Revise the `score.py` script. You can look at the deployment logs by running `print(aci_service.get_logs())` to see where the issue is.\n",
    "1. After fixing the issue, delete the current service by running `aci_service.delete()`.\n",
    "1. Rerun the last two cells to initialize and deploy a new service.\n",
    "\n",
    "Unlike in the local deployment setting, it is not possible to update a publicly deployed service. Make sure to check your code carefully before deploying, so that you don't need to delete and redeploy too many times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nWCJvHgIFyTq"
   },
   "source": [
    "After the deployment finishes successfully, you can get the web service's HTTP endpoint, which accepts REST client calls. This endpoint can be shared with anyone who wants to test the web service. The following code cell will also write the endpoint to a text file, which will be collected by the `submitter` executable when you make a submission to Sail()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gather": {
     "logged": 1711547143540
    },
    "id": "-J_IAvxLFyyM",
    "outputId": "564887ce-0abd-4022-c2ea-d9c0b027a9da",
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "print(aci_service.scoring_uri)\n",
    "with open('scoring_uri.txt', 'w') as f:\n",
    "    f.write(aci_service.scoring_uri)\n",
    "    print('Save scoring uri successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mZO00rc2F0of"
   },
   "source": [
    "**Step 7: Test the public web service**\n",
    "\n",
    "Finally, let's test this public endpoint with the same test cases we used earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1711547143554
    },
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "def ping_endpoint(flattened_img, uri = None):\n",
    "    if uri is None:\n",
    "        uri = open(\"scoring_uri.txt\", \"r\").read()\n",
    "    input_json = json.dumps({\n",
    "        \"image\" : flattened_img\n",
    "    })\n",
    "    headers = {'Content-Type' : 'application/json'}\n",
    "    response = requests.post(uri, bytes(input_json, encoding = \"utf-8\"), headers = headers)\n",
    "    return response.status_code, json.loads(response.content.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gather": {
     "logged": 1711547143569
    },
    "id": "WLPaEe20SNxY",
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "def test_aci_deployment():\n",
    "    # cifar-10 image\n",
    "    cifar_img, label = full_valset[3]\n",
    "    show_cifar_image(cifar_img)\n",
    "    print(\"Ground truth label: \", classes[label])\n",
    "    status_code, content = ping_endpoint(cifar_img.unsqueeze(0).numpy().tolist())\n",
    "    assert status_code == 200\n",
    "    print(content)\n",
    "    assert content['trained_AlexNet.pt'] == {'label': 'car', 'probability': '0.89'}, content['trained_AlexNet.pt']\n",
    "    assert content['trained_LeNet.pt'] == {'label': 'car', 'probability': '0.91'}, content['trained_LeNet.pt'] \n",
    "    assert content['trained_LogisticRegression.pt'] == {'label': 'car', 'probability': '0.62'}, content['trained_LogisticRegression.pt']\n",
    "    print(\"Fine tuned model's prediction:\", [pred for name, pred in content.items() if 'tuned' in name][0])\n",
    "\n",
    "    # external image\n",
    "    external_img = Image.open('test_img.jpg')\n",
    "    plt.imshow(external_img)\n",
    "    print(\"Groud truth label: bird\")\n",
    "    external_img_formatted = preprocess(external_img)\n",
    "    status_code, content = ping_endpoint(external_img_formatted.tolist())\n",
    "    print(content)\n",
    "    assert content['trained_AlexNet.pt'] == {'label': 'frog', 'probability': '0.52'}, content['trained_AlexNet.pt'] \n",
    "    assert content['trained_LeNet.pt'] == {'label': 'car', 'probability': '0.24'}, content['trained_LeNet.pt']\n",
    "    assert content['trained_LogisticRegression.pt'] == {'label': 'car', 'probability': '0.82'}, content['trained_LogisticRegression.pt']\n",
    "    print(\"Fine tuned model's prediction:\", [pred for name, pred in content.items() if 'tuned' in name][0])\n",
    "    \n",
    "    print(\"All tests passed\")\n",
    "\n",
    "test_aci_deployment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qc_8mggoGOeI"
   },
   "source": [
    "**Cleaning up cloud resources**\n",
    "\n",
    "You have completed all the questions in this project! One last step you need to do is to make sure you clean up your resources properly, so that no unexpected charge is incurred.\n",
    "\n",
    "Use the left navigation bar in the Azure Machine Learning Studio to manage your computes and endpoints. If you don't anticipate any further usage of Azure GPU for this project, you should go back to the [Azure homepage](https://portal.azure.com/) and delete the entire resource group, as the resource group itself also incurs charges over time, even without any computes or endpoints.\n",
    "\n",
    "![endpoints](http://clouddatascience.blob.core.windows.net/m20-foundation-data-science/p5-model-deployment-comparison/managing_endpoints.png)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "colab": {
   "collapsed_sections": [],
   "name": "Compare model performance on CPUs and GPUs.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
